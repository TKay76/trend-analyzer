#!/usr/bin/env python3
"""
YouTube Charts CSV Scraper
YouTube Charts í˜ì´ì§€ì—ì„œ CSV íŒŒì¼ì„ ë‹¤ìš´ë¡œë“œí•˜ì—¬ ì •í™•í•œ ì°¨íŠ¸ ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•©ë‹ˆë‹¤.
"""

import os
import sys
import csv
import time
import tempfile
from datetime import datetime
from pathlib import Path
from playwright.sync_api import sync_playwright

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ ì¶”ê°€
sys.path.append(os.path.join(os.path.dirname(__file__), '..', '..'))
from src.database import database_manager as db
from src.utils.logger_config import get_logger, log_scraper_start, log_scraper_end, log_error_with_context

# ë¡œê±° ì„¤ì •
logger = get_logger(__name__)

def extract_youtube_id_from_url(youtube_url):
    """
    YouTube URLì—ì„œ ë¹„ë””ì˜¤ IDë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.
    ì˜ˆ: https://www.youtube.com/watch?v=983bBbJx0Mk -> 983bBbJx0Mk
    """
    if not youtube_url:
        return None
    
    if 'watch?v=' in youtube_url:
        return youtube_url.split('watch?v=')[1].split('&')[0]
    return None

def generate_shorts_url(youtube_id):
    """
    YouTube IDë¡œë¶€í„° Shorts ê²€ìƒ‰ URLì„ ìƒì„±í•©ë‹ˆë‹¤.
    ì˜ˆ: 983bBbJx0Mk -> https://www.youtube.com/source/983bBbJx0Mk/shorts
    """
    if not youtube_id:
        return None
    return f"https://www.youtube.com/source/{youtube_id}/shorts"

def analyze_chart_position(current_rank, previous_rank, periods_on_chart):
    """
    ì°¨íŠ¸ ìˆœìœ„ ë³€í™”ë¥¼ ë¶„ì„í•˜ì—¬ íƒœê·¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
    
    Returns:
        tuple: (is_trending, is_new_hit)
    """
    is_trending = False
    is_new_hit = False
    
    # ì‹ ê³¡ íŒë‹¨: ì´ì „ ìˆœìœ„ê°€ "n/a"
    if previous_rank == "n/a":
        is_new_hit = True
    
    # ì¸ê¸°ê¸‰ìƒìŠ¹ íŒë‹¨: ì´ì „ ìˆœìœ„ë³´ë‹¤ 5ìœ„ ì´ìƒ ìƒìŠ¹
    try:
        if previous_rank != "n/a" and previous_rank.isdigit():
            prev_rank_num = int(previous_rank)
            curr_rank_num = int(current_rank)
            if prev_rank_num - curr_rank_num >= 5:  # ìˆœìœ„ê°€ ìƒìŠ¹ (ìˆ«ìê°€ ì‘ì•„ì§)
                is_trending = True
    except (ValueError, TypeError):
        pass
    
    return is_trending, is_new_hit

def download_youtube_csv():
    """
    YouTube Charts í˜ì´ì§€ì—ì„œ CSV íŒŒì¼ì„ ë‹¤ìš´ë¡œë“œí•©ë‹ˆë‹¤.
    
    Returns:
        str: ë‹¤ìš´ë¡œë“œëœ CSV íŒŒì¼ ê²½ë¡œ, ì‹¤íŒ¨ì‹œ None
    """
    target_url = "https://charts.youtube.com/charts/TopShortsSongs/kr/daily"
    
    # CSV ì €ì¥ í´ë” ì„¤ì •
    csv_dir = os.path.join(os.path.dirname(__file__), '..', '..', 'data', 'csv_downloads')
    os.makedirs(csv_dir, exist_ok=True)
    
    logger.info(f"ğŸ“Š YouTube Charts CSV ë‹¤ìš´ë¡œë“œ ì‹œì‘: {target_url}")
    
    with sync_playwright() as p:
        browser = p.chromium.launch(headless=False)  # ë””ë²„ê¹…ì„ ìœ„í•´ ë¸Œë¼ìš°ì € í‘œì‹œ
        context = browser.new_context(accept_downloads=True)
        page = context.new_page()
        
        try:
            # í˜ì´ì§€ ë¡œë”©
            logger.info("ğŸŒ í˜ì´ì§€ ë¡œë”© ì¤‘...")
            page.goto(target_url, wait_until="domcontentloaded")
            page.wait_for_timeout(5000)
            
            # ë‹¤ìš´ë¡œë“œ ë²„íŠ¼ ì°¾ê¸° ë° í´ë¦­
            logger.info("ğŸ”½ CSV ë‹¤ìš´ë¡œë“œ ë²„íŠ¼ í´ë¦­ ì¤‘...")
            
            # í˜ì´ì§€ì˜ ëª¨ë“  ë²„íŠ¼ ìš”ì†Œë“¤ì„ í™•ì¸
            logger.info("ğŸ” í˜ì´ì§€ì—ì„œ ë‹¤ìš´ë¡œë“œ ê´€ë ¨ ìš”ì†Œ ì°¾ëŠ” ì¤‘...")
            
            # ëª¨ë“  ë²„íŠ¼ê³¼ ë§í¬ ìš”ì†Œ í™•ì¸
            all_buttons = page.locator("button, a, .button, [role='button']").all()
            logger.info(f"ì´ {len(all_buttons)}ê°œì˜ í´ë¦­ ê°€ëŠ¥í•œ ìš”ì†Œ ë°œê²¬")
            
            # ì‹¤ì œ ë°œê²¬ëœ ë‹¤ìš´ë¡œë“œ ë²„íŠ¼ ì„ íƒìë“¤
            download_selectors = [
                "#download-button",  # ì‹¤ì œ ë°œê²¬ëœ ID
                "paper-icon-button#download-button",  # ì •í™•í•œ íƒœê·¸ì™€ ID
                "paper-icon-button[title='download']",  # title ì†ì„±ìœ¼ë¡œ ì°¾ê¸°
                "paper-icon-button[icon='ytmc-icons-ext:download-white-fill']",  # ì•„ì´ì½˜ìœ¼ë¡œ ì°¾ê¸°
                ".ytmc-top-banner paper-icon-button",  # í´ë˜ìŠ¤ ì»¨í…Œì´ë„ˆ ë‚´ì—ì„œ ì°¾ê¸°
                "paper-icon-button[role='button'][title='download']",  # ë³µí•© ì†ì„±
                "[title='download']",  # titleë§Œìœ¼ë¡œ
                "button[title='download']",  # ì¼ë°˜ ë²„íŠ¼ í˜•íƒœ
                "#download",  # í˜¹ì‹œ ëª¨ë¥¼ ë‹¤ë¥¸ ID
                "button[aria-label*='Download']",
                "button[aria-label*='ë‹¤ìš´ë¡œë“œ']"
            ]
            
            download_clicked = False
            
            # ë‹¤ìš´ë¡œë“œ ë²„íŠ¼ ì§ì ‘ í´ë¦­ ì‹œë„ (ìƒë‹¨ ë©”ë‰´ì— ìœ„ì¹˜)
            for selector in download_selectors:
                try:
                    if page.locator(selector).count() > 0:
                        logger.info(f"ğŸ”½ ë‹¤ìš´ë¡œë“œ ë²„íŠ¼ ì‹œë„: {selector}")
                        
                        # ë²„íŠ¼ì´ ë³´ì´ëŠ”ì§€ í™•ì¸
                        if page.locator(selector).is_visible():
                            # ë‹¤ìš´ë¡œë“œ ì‹œì‘ ëŒ€ê¸°
                            with page.expect_download() as download_info:
                                page.locator(selector).click(timeout=10000)
                            
                            download = download_info.value
                            
                            # íŒŒì¼ ì €ì¥
                            csv_filename = f"youtube_charts_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv"
                            csv_path = os.path.join(csv_dir, csv_filename)
                            download.save_as(csv_path)
                            
                            logger.info(f"âœ… CSV ë‹¤ìš´ë¡œë“œ ì™„ë£Œ: {csv_path}")
                            download_clicked = True
                            break
                        else:
                            logger.debug(f"ì„ íƒì {selector}ëŠ” ì¡´ì¬í•˜ì§€ë§Œ ë³´ì´ì§€ ì•ŠìŒ")
                        
                except Exception as e:
                    logger.debug(f"ì„ íƒì {selector} ì‹œë„ ì‹¤íŒ¨: {e}")
                    continue
            
            if not download_clicked:
                logger.error("âŒ ë‹¤ìš´ë¡œë“œ ë²„íŠ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
                return None
                
            return csv_path
            
        except Exception as e:
            log_error_with_context(logger, e, "CSV ë‹¤ìš´ë¡œë“œ")
            return None
        finally:
            browser.close()

def parse_csv_data(csv_path):
    """
    ë‹¤ìš´ë¡œë“œëœ CSV íŒŒì¼ì„ íŒŒì‹±í•©ë‹ˆë‹¤.
    
    Returns:
        list: íŒŒì‹±ëœ ê³¡ ë°ì´í„° ë¦¬ìŠ¤íŠ¸
    """
    if not csv_path or not os.path.exists(csv_path):
        logger.error("âŒ CSV íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤")
        return []
    
    songs_data = []
    
    try:
        with open(csv_path, 'r', encoding='utf-8') as file:
            csv_reader = csv.DictReader(file)
            
            for row in csv_reader:
                try:
                    # ê¸°ë³¸ ë°ì´í„° ì¶”ì¶œ
                    rank = row.get('Rank', '').strip()
                    previous_rank = row.get('Previous Rank', '').strip()
                    title = row.get('Track Name', '').strip()
                    artist = row.get('Artist Names', '').strip()
                    periods_on_chart = row.get('Periods on Chart', '0').strip()
                    youtube_url = row.get('YouTube URL', '').strip()
                    
                    # YouTube ID ì¶”ì¶œ (ì—†ì–´ë„ ì €ì¥í•¨)
                    youtube_id = extract_youtube_id_from_url(youtube_url)
                    
                    # Shorts URL ìƒì„±
                    shorts_url = generate_shorts_url(youtube_id)
                    
                    # íƒœê·¸ ë¶„ì„
                    is_trending, is_new_hit = analyze_chart_position(
                        rank, previous_rank, periods_on_chart
                    )
                    
                    song_data = {
                        'rank': rank,
                        'previous_rank': previous_rank,
                        'title': title,
                        'artist': artist,
                        'periods_on_chart': periods_on_chart,
                        'youtube_url': youtube_url,
                        'youtube_id': youtube_id,  # Noneì¼ ìˆ˜ ìˆìŒ
                        'shorts_url': shorts_url,  # UGC ì¹´ìš´í„°ìš© URL
                        'is_trending': is_trending,
                        'is_new_hit': is_new_hit
                    }
                    
                    songs_data.append(song_data)
                    
                except Exception as e:
                    logger.warning(f"âš ï¸ í–‰ íŒŒì‹± ì‹¤íŒ¨: {row}, ì˜¤ë¥˜: {e}")
                    continue
        
        logger.info(f"âœ… CSV íŒŒì‹± ì™„ë£Œ: {len(songs_data)}ê³¡ ì²˜ë¦¬ë¨")
        return songs_data
        
    except Exception as e:
        log_error_with_context(logger, e, "CSV íŒŒì‹±")
        return []

def save_to_database(songs_data):
    """
    íŒŒì‹±ëœ ë°ì´í„°ë¥¼ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥í•©ë‹ˆë‹¤.
    YouTube IDê°€ ì—†ì–´ë„ ê³¡ ì •ë³´ëŠ” ì €ì¥ë©ë‹ˆë‹¤.
    """
    if not songs_data:
        logger.error("âŒ ì €ì¥í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤")
        return 0
    
    logger.info(f"ğŸ’¾ ë°ì´í„°ë² ì´ìŠ¤ì— {len(songs_data)}ê³¡ ì €ì¥ ì¤‘...")
    
    total_saved = 0
    trending_count = 0
    new_hit_count = 0
    no_id_count = 0
    
    for song in songs_data:
        try:
            # ê³¡ ì €ì¥ (YouTube IDê°€ Noneì´ì–´ë„ ì €ì¥)
            song_id = db.add_song_and_get_id(
                title=song['title'],
                artist=song['artist'],
                youtube_id=song['youtube_id']  # Noneì¼ ìˆ˜ ìˆìŒ
            )
            
            if song_id:
                # íŠ¸ë Œë“œ ë°ì´í„° ì €ì¥
                db.add_trend(
                    song_id=song_id,
                    source='youtube',
                    category='trending',
                    rank=song['rank'],
                    metrics={
                        'previous_rank': song['previous_rank'],
                        'periods_on_chart': song['periods_on_chart'],
                        'youtube_url': song['youtube_url'],
                        'shorts_url': song['shorts_url']
                    }
                )
                
                # íƒœê·¸ ì—…ë°ì´íŠ¸
                if song['is_trending'] or song['is_new_hit']:
                    db.update_song_tags(
                        title=song['title'],
                        artist=song['artist'],
                        is_trending=song['is_trending'],
                        is_new_hit=song['is_new_hit']
                    )
                    
                    if song['is_trending']:
                        trending_count += 1
                    if song['is_new_hit']:
                        new_hit_count += 1
                
                # YouTube ID ì—†ëŠ” ê³¡ ì¹´ìš´íŠ¸
                if not song['youtube_id']:
                    no_id_count += 1
                
                total_saved += 1
                
        except Exception as e:
            log_error_with_context(logger, e, f"ê³¡ ì €ì¥: {song['title']}")
    
    logger.info(f"âœ… ë°ì´í„° ì €ì¥ ì™„ë£Œ:")
    logger.info(f"  ğŸ“Š ì´ ì €ì¥: {total_saved}ê³¡")
    logger.info(f"  ğŸ”¥ ì¸ê¸°ê¸‰ìƒìŠ¹: {trending_count}ê³¡")
    logger.info(f"  â­ ì‹ ê³¡: {new_hit_count}ê³¡")
    logger.info(f"  âš ï¸ YouTube ID ì—†ìŒ: {no_id_count}ê³¡ (UGC ìˆ˜ì§‘ ë¶ˆê°€)")
    
    return total_saved

def scrape_youtube_charts_csv():
    """
    YouTube Charts CSV ìŠ¤í¬ë˜í•‘ ë©”ì¸ í•¨ìˆ˜
    """
    start_time = time.time()
    log_scraper_start(logger, "YouTube Charts CSV ìŠ¤í¬ë˜í¼", "CSV Download")
    
    try:
        # 1. CSV ë‹¤ìš´ë¡œë“œ
        csv_path = download_youtube_csv()
        if not csv_path:
            return False
        
        # 2. CSV íŒŒì‹±
        songs_data = parse_csv_data(csv_path)
        if not songs_data:
            return False
        
        # 3. ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥
        saved_count = save_to_database(songs_data)
        
        # 4. CSV íŒŒì¼ ë³´ì¡´ (ì„ì‹œ íŒŒì¼ì´ ì•„ë‹ˆë¯€ë¡œ ì‚­ì œí•˜ì§€ ì•ŠìŒ)
        logger.info(f"ğŸ“ CSV íŒŒì¼ ì €ì¥ ìœ„ì¹˜: {csv_path}")
        
        # ê²°ê³¼ ë¡œê¹…
        duration = time.time() - start_time
        log_scraper_end(logger, "YouTube Charts CSV ìŠ¤í¬ë˜í¼", saved_count > 0, duration, saved_count)
        
        return saved_count > 0
        
    except Exception as e:
        log_error_with_context(logger, e, "YouTube CSV ìŠ¤í¬ë˜í•‘")
        return False

if __name__ == "__main__":
    # ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™”
    logger.info("ğŸ’¾ ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™” ì¤‘...")
    db.create_tables()
    logger.info("âœ… ë°ì´í„°ë² ì´ìŠ¤ ì¤€ë¹„ ì™„ë£Œ.")
    
    # CSV ìŠ¤í¬ë˜í•‘ ì‹¤í–‰
    success = scrape_youtube_charts_csv()
    
    if success:
        logger.info("ğŸ‰ YouTube CSV ìŠ¤í¬ë˜í•‘ ì™„ë£Œ!")
    else:
        logger.error("âŒ YouTube CSV ìŠ¤í¬ë˜í•‘ ì‹¤íŒ¨!")
        sys.exit(1)