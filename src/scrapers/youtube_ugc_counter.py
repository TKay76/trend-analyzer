import sys
import re
from playwright.sync_api import sync_playwright
from bs4 import BeautifulSoup

def parse_video_count(count_str):
    """
    Parses a string like '1.4M videos', '12ë§Œê°œ' or '1,400,000 videos' into an integer.
    """
    if not count_str:
        return 0
        
    count_str = count_str.lower().replace('videos', '').replace('video', '').replace('shorts', '').replace('short', '').replace('ê°œ', '').strip()
    count_str = count_str.replace(',', '')

    try:
        # Korean number units
        if 'ë§Œ' in count_str:
            return int(float(count_str.replace('ë§Œ', '')) * 10000)
        elif 'ì–µ' in count_str:
            return int(float(count_str.replace('ì–µ', '')) * 100000000)
        elif 'ì²œ' in count_str:
            return int(float(count_str.replace('ì²œ', '')) * 1000)
        elif 'ë°±' in count_str:
            return int(float(count_str.replace('ë°±', '')) * 100)
        elif 'ì‹­' in count_str:
            return int(float(count_str.replace('ì‹­', '')) * 10)
        # English units
        elif 'k' in count_str:
            return int(float(count_str.replace('k', '')) * 1000)
        elif 'm' in count_str:
            return int(float(count_str.replace('m', '')) * 1000000)
        elif 'b' in count_str:
            return int(float(count_str.replace('b', '')) * 1000000000)
        else:
            return int(float(count_str))
    except (ValueError, TypeError):
        return 0

def scrape_youtube_shorts_data(url):
    """
    Scrapes the total video count for a given YouTube Shorts URL.
    Returns the count as integer, or 0 if no count found.
    """
    print(f"ğŸ“º YouTube UGC ìˆ˜ì§‘: {url}")
    
    with sync_playwright() as p:
        browser = p.chromium.launch(headless=True) # Set to False for visual debugging
        page = browser.new_page()
        
        try:
            # Navigate to page
            page.goto(url, wait_until="domcontentloaded")
            print("  â³ í˜ì´ì§€ ë¡œë”© ì¤‘...")

            # Wait for content to load
            page.wait_for_timeout(8000)  # ë” ê¸´ ëŒ€ê¸° ì‹œê°„
            
            # Scroll to load more content
            page.evaluate("window.scrollTo(0, document.body.scrollHeight)")
            page.wait_for_timeout(3000)
            
            # Get page content
            html_content = page.content()
            soup = BeautifulSoup(html_content, 'html.parser')

            # Get all text content from the page
            all_text = soup.get_text()
            
            # Debug: Print some page text to see what we're getting
            print(f"  ğŸ” í˜ì´ì§€ í…ìŠ¤íŠ¸ ìƒ˜í”Œ: {all_text[:200].strip()}...")
            
            # Look for video count patterns (Korean and English)
            patterns = [
                r'(\d+[.,]?\d*[ë§Œì–µì²œë°±ì‹­]?)\s*ê°œ',  # 12ë§Œê°œ
                r'(\d+[.,]?\d*[KMB]?)\s*(?:videos?|shorts?)',
                r'(\d+[.,]?\d*[KMB]?)\s*(?:video|short)',
                r'(\d+[.,]?\d*[ë§Œì–µì²œë°±ì‹­]?)\s*(?:ê°œì˜?\s*)?(?:ë™ì˜ìƒ|ì‡¼ì¸ )',
                r'(\d+[.,]?\d*[KMB]?)\s*ê²°ê³¼',
            ]
            
            found_counts = []
            
            # Search for video count patterns
            for pattern in patterns:
                matches = re.findall(pattern, all_text, re.IGNORECASE)
                if matches:
                    for match in matches:
                        try:
                            count = parse_video_count(match)
                            if count > 0:
                                found_counts.append(count)
                                print(f"  ğŸ“Š ë°œê²¬ëœ ì¹´ìš´íŠ¸: {match} â†’ {count:,}")
                        except Exception as e:
                            print(f"  âš ï¸ íŒŒì‹± ì‹¤íŒ¨: {match} ({e})")
                            continue
            
            # Return the highest count found (most likely to be the total)
            if found_counts:
                result = max(found_counts)
                print(f"  âœ… ìµœì¢… ê²°ê³¼: {result:,}ê°œ")
                return result
            else:
                print(f"  âŒ ë¹„ë””ì˜¤ ì¹´ìš´íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ")
                return 0
                
        except Exception as e:
            print(f"  ğŸ’¥ ì˜¤ë¥˜: {e}")
            return 0
        finally:
            browser.close()

if __name__ == "__main__":
    if len(sys.argv) < 2:
        print("Usage: python youtube_shorts_scraper.py <YouTube_Shorts_URL>")
        sys.exit(1)

    youtube_url = sys.argv[1]
    video_count = scrape_youtube_shorts_data(youtube_url)
    print(video_count)