import sys
import re
import os
import time
from playwright.sync_api import sync_playwright
from bs4 import BeautifulSoup

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ ì¶”ê°€
sys.path.append(os.path.join(os.path.dirname(__file__), '..', '..'))
from src.utils.logger_config import get_logger, log_error_with_context
from src.database import database_manager as db

# ë¡œê±° ì„¤ì •
logger = get_logger(__name__)

def parse_video_count(count_str):
    """
    Parses a string like '1.4M videos', '12ë§Œê°œ' or '1,400,000 videos' into an integer.
    """
    if not count_str:
        return 0
        
    count_str = count_str.lower().replace('videos', '').replace('video', '').replace('shorts', '').replace('short', '').replace('ê°œ', '').strip()
    count_str = count_str.replace(',', '')

    try:
        # Korean number units
        if 'ë§Œ' in count_str:
            return int(float(count_str.replace('ë§Œ', '')) * 10000)
        elif 'ì–µ' in count_str:
            return int(float(count_str.replace('ì–µ', '')) * 100000000)
        elif 'ì²œ' in count_str:
            return int(float(count_str.replace('ì²œ', '')) * 1000)
        elif 'ë°±' in count_str:
            return int(float(count_str.replace('ë°±', '')) * 100)
        elif 'ì‹­' in count_str:
            return int(float(count_str.replace('ì‹­', '')) * 10)
        # English units
        elif 'k' in count_str:
            return int(float(count_str.replace('k', '')) * 1000)
        elif 'm' in count_str:
            return int(float(count_str.replace('m', '')) * 1000000)
        elif 'b' in count_str:
            return int(float(count_str.replace('b', '')) * 1000000000)
        else:
            return int(float(count_str))
    except (ValueError, TypeError):
        return 0

def extract_video_count_with_selectors(page):
    """
    íŠ¹ì • ì„ íƒìë¥¼ ì‚¬ìš©í•´ ë¹„ë””ì˜¤ ì¹´ìš´íŠ¸ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.
    """
    selectors = [
        # YouTube ê³µí†µ ì„ íƒìë“¤
        '[data-testid*="count"]',
        '.ytd-shelf-header-renderer .title',
        '#contents-count',
        '.metadata-stats-count',
        # í—¤ë”ë‚˜ ì œëª© ì˜ì—­ì—ì„œ ì°¾ê¸°
        'h1:has-text("videos")',
        'h1:has-text("ê°œ")',
        'h2:has-text("videos")',
        'h2:has-text("ê°œ")',
        # ì¼ë°˜ì ì¸ ì¹´ìš´íŠ¸ í‘œì‹œ ì˜ì—­
        '.count',
        '.video-count',
        '.results-count'
    ]
    
    for selector in selectors:
        try:
            elements = page.locator(selector).all()
            for element in elements:
                text = element.text_content()
                if text:
                    count = extract_count_from_text(text.strip())
                    if count > 0:
                        logger.debug(f"ğŸ“Š ì„ íƒì {selector}ì—ì„œ ì¹´ìš´íŠ¸ ë°œê²¬: {text} â†’ {count:,}")
                        return count
        except Exception as e:
            logger.debug(f"ì„ íƒì {selector} ì‹¤íŒ¨: {e}")
            continue
    
    return 0

def extract_count_from_text(text):
    """
    í…ìŠ¤íŠ¸ì—ì„œ ìˆ«ìì™€ ë‹¨ìœ„ë¥¼ ì¶”ì¶œí•˜ì—¬ ì¹´ìš´íŠ¸ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
    """
    patterns = [
        r'(\d+[.,]?\d*[ë§Œì–µì²œë°±ì‹­]?)\s*ê°œ',  # 12ë§Œê°œ
        r'(\d+[.,]?\d*[KMB]?)\s*(?:videos?|shorts?)',
        r'(\d+[.,]?\d*[KMB]?)\s*(?:video|short)',
        r'(\d+[.,]?\d*[ë§Œì–µì²œë°±ì‹­]?)\s*(?:ê°œì˜?\s*)?(?:ë™ì˜ìƒ|ì‡¼ì¸ )',
        r'(\d+[.,]?\d*[KMB]?)\s*ê²°ê³¼',
    ]
    
    for pattern in patterns:
        matches = re.findall(pattern, text, re.IGNORECASE)
        if matches:
            for match in matches:
                count = parse_video_count(match)
                if count > 0:
                    return count
    return 0

def extract_video_count_from_text(all_text):
    """
    ì „ì²´ í…ìŠ¤íŠ¸ì—ì„œ ë¹„ë””ì˜¤ ì¹´ìš´íŠ¸ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.
    """
    patterns = [
        r'(\d+[.,]?\d*[ë§Œì–µì²œë°±ì‹­]?)\s*ê°œ',  # 12ë§Œê°œ
        r'(\d+[.,]?\d*[KMB]?)\s*(?:videos?|shorts?)',
        r'(\d+[.,]?\d*[KMB]?)\s*(?:video|short)',
        r'(\d+[.,]?\d*[ë§Œì–µì²œë°±ì‹­]?)\s*(?:ê°œì˜?\s*)?(?:ë™ì˜ìƒ|ì‡¼ì¸ )',
        r'(\d+[.,]?\d*[KMB]?)\s*ê²°ê³¼',
    ]
    
    found_counts = []
    
    for pattern in patterns:
        matches = re.findall(pattern, all_text, re.IGNORECASE)
        if matches:
            for match in matches:
                try:
                    count = parse_video_count(match)
                    if count > 0:
                        found_counts.append(count)
                        logger.debug(f"ğŸ“Š ë°œê²¬ëœ ì¹´ìš´íŠ¸: {match} â†’ {count:,}")
                except Exception as e:
                    logger.debug(f"âš ï¸ íŒŒì‹± ì‹¤íŒ¨: {match} ({e})")
                    continue
    
    # ê°€ì¥ í° ê°’ ë°˜í™˜ (ì „ì²´ ê°œìˆ˜ì¼ ê°€ëŠ¥ì„±ì´ ë†’ìŒ)
    return max(found_counts) if found_counts else 0


def scrape_youtube_shorts_data(url):
    """
    Scrapes the total video count for a given YouTube Shorts URL.
    Supports both watch URLs and source/shorts URLs.
    Returns the count as integer, or 0 if no count found.
    """
    # YouTube IDì—ì„œ Shorts URLë¡œ ë³€í™˜
    if '/watch?v=' in url:
        video_id = url.split('watch?v=')[1].split('&')[0]
        url = f"https://www.youtube.com/source/{video_id}/shorts"
    
    logger.info(f"ğŸ“º YouTube UGC ìˆ˜ì§‘: {url}")
    
    with sync_playwright() as p:
        browser = p.chromium.launch(
            headless=True,
            args=['--no-sandbox', '--disable-dev-shm-usage']
        )
        page = browser.new_page()
        
        # íƒ€ì„ì•„ì›ƒ ì„¤ì •
        page.set_default_timeout(30000)  # 30ì´ˆ
        
        try:
            logger.info("ğŸŒ í˜ì´ì§€ ë¡œë”© ì¤‘...")
            page.goto(url, wait_until="networkidle", timeout=20000)
            
            # ë¹„ë””ì˜¤ ì¹´ìš´íŠ¸ ìš”ì†Œê°€ ë‚˜íƒ€ë‚  ë•Œê¹Œì§€ ëŒ€ê¸° (ìµœëŒ€ 15ì´ˆ)
            try:
                page.wait_for_selector(
                    'text=/\\d+[.,]?\\d*[KMBë§Œì–µì²œë°±ì‹­]?\\s*(?:videos?|shorts?|ê°œ|ê²°ê³¼)/', 
                    timeout=15000
                )
                logger.debug("âœ… ë¹„ë””ì˜¤ ì¹´ìš´íŠ¸ ìš”ì†Œ ë°œê²¬")
            except Exception:
                logger.warning("âš ï¸ ë¹„ë””ì˜¤ ì¹´ìš´íŠ¸ ìš”ì†Œ ëŒ€ê¸° íƒ€ì„ì•„ì›ƒ, ê³„ì† ì§„í–‰")
            
            # ì§§ì€ ìŠ¤í¬ë¡¤ë¡œ ì¶”ê°€ ì½˜í…ì¸  ë¡œë”©
            page.evaluate("window.scrollTo(0, 500)")
            time.sleep(2)
            
            # íŠ¹ì • ì˜ì—­ì—ì„œ ë¹„ë””ì˜¤ ì¹´ìš´íŠ¸ ì°¾ê¸°
            video_count = extract_video_count_with_selectors(page)
            
            if video_count > 0:
                logger.info(f"âœ… ìµœì¢… ê²°ê³¼: {video_count:,}ê°œ")
                return video_count
            
            # ì„ íƒìë¡œ ì°¾ì§€ ëª»í•œ ê²½ìš° ì „ì²´ í…ìŠ¤íŠ¸ì—ì„œ ê²€ìƒ‰
            html_content = page.content()
            soup = BeautifulSoup(html_content, 'html.parser')
            all_text = soup.get_text()
            
            logger.debug(f"ğŸ” í˜ì´ì§€ í…ìŠ¤íŠ¸ ìƒ˜í”Œ: {all_text[:200].strip()}...")
            
            # í…ìŠ¤íŠ¸ì—ì„œ ë¹„ë””ì˜¤ ì¹´ìš´íŠ¸ íŒ¨í„´ ê²€ìƒ‰
            video_count = extract_video_count_from_text(all_text)
            
            if video_count > 0:
                logger.info(f"âœ… ìµœì¢… ê²°ê³¼: {video_count:,}ê°œ")
                return video_count
            else:
                logger.warning("âŒ ë¹„ë””ì˜¤ ì¹´ìš´íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ")
                return 0
                
        except Exception as e:
            log_error_with_context(logger, e, "YouTube Shorts í˜ì´ì§€ ìŠ¤í¬ë˜í•‘")
            return 0
        finally:
            browser.close()

def save_to_database(youtube_url, video_count):
    """ìˆ˜ì§‘ëœ YouTube UGC ì¹´ìš´íŠ¸ë¥¼ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥"""
    if video_count <= 0:
        return False
    
    # YouTube URLì—ì„œ YouTube ID ì¶”ì¶œ
    if '/source/' in youtube_url and '/shorts' in youtube_url:
        youtube_id = youtube_url.split('/source/')[1].split('/shorts')[0]
    elif '/watch?v=' in youtube_url:
        youtube_id = youtube_url.split('watch?v=')[1].split('&')[0]
    else:
        logger.warning("âŒ YouTube IDë¥¼ ì¶”ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
        return False
    
    try:
        # í•´ë‹¹ YouTube IDë¥¼ ê°€ì§„ ê³¡ ì°¾ê¸°
        songs = db.get_songs_with_platform_ids('youtube')
        target_song = None
        
        for song in songs:
            if len(song) >= 4 and song[3] == youtube_id:  # youtube_id ì»¬ëŸ¼
                target_song = song
                break
        
        if not target_song:
            logger.warning(f"âŒ YouTube ID {youtube_id}ì— í•´ë‹¹í•˜ëŠ” ê³¡ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
            return False
        
        song_id = target_song[0]
        title = target_song[1]
        artist = target_song[2]
        
        # UGC ì¹´ìš´íŠ¸ ì €ì¥
        db.update_ugc_counts(song_id, youtube_count=video_count)
        logger.info(f"âœ… UGC ì¹´ìš´íŠ¸ ì €ì¥: {title} - {artist} â†’ {video_count:,}ê°œ")
        
        return True
        
    except Exception as e:
        log_error_with_context(logger, e, "ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥")
        return False

if __name__ == "__main__":
    if len(sys.argv) < 2:
        print("ì‚¬ìš©ë²•:")
        print("  python youtube_ugc_counter.py <YouTube_Shorts_URL> [--save-db]")
        print("\nğŸ’¡ YouTube Shorts URL ì˜ˆì‹œ:")
        print("  https://www.youtube.com/source/983bBbJx0Mk/shorts")
        print("\nğŸ’¾ ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥:")
        print("  python youtube_ugc_counter.py <URL> --save-db")
        sys.exit(1)

    youtube_url = sys.argv[1]
    save_to_db = '--save-db' in sys.argv
    
    video_count = scrape_youtube_shorts_data(youtube_url)
    print(video_count)
    
    # ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥
    if save_to_db and video_count > 0:
        if save_to_database(youtube_url, video_count):
            print("ğŸ’¾ ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥ ì™„ë£Œ!")
        else:
            print("âŒ ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥ ì‹¤íŒ¨!")