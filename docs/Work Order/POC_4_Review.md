# PoC Review: Trend Analysis Database Construction & Scraper Integration

## 1. 기능 요약

`workorder 04`의 목표였던 스크래핑 데이터의 영구 저장을 위한 데이터 파이프라인 MVP(Minimum Viable Product)를 성공적으로 구축했습니다. 기존의 PoC 스크레이퍼들이 실제 데이터를 축적하는 시스템으로 통합되었습니다.

주요 기능은 다음과 같습니다:
- **중앙 데이터베이스 구축:** 개발 초기 단계의 속도와 편의성을 위해, 별도 설치가 필요 없는 **SQLite**를 사용하여 `trend_analysis.db` 데이터베이스를 구축했습니다.
- **데이터베이스 스키마 설계:** 데이터 정규화를 통해 `songs`(노래 정보 마스터)와 `daily_trends`(일일 순위 정보) 두 개의 테이블로 스키마를 설계하여 데이터 중복을 최소화하고 확장성을 확보했습니다.
- **데이터베이스 관리 모듈화:** 데이터베이스 연결, 테이블 생성, 데이터 삽입(Upsert) 등 모든 DB 관련 로직을 `database_manager.py` 모듈로 중앙화하여, 코드의 재사용성을 높이고 향후 유지보수를 용이하게 만들었습니다.
- **스크레이퍼 연동:** `tiktok_music_scraper.py`와 `youtube_music_scraper.py`가 콘솔에 결과를 출력하는 대신, `database_manager` 모듈을 통해 수집한 데이터를 `trend_analysis.db`에 직접 저장하도록 수정했습니다.
- **통합 실행 스크립트:** `run_all_scrapers.sh` 셸 스크립트를 작성하여, 단일 명령어로 모든 스크레이퍼를 안전하게 순차 실행할 수 있도록 자동화했습니다.

이 구현은 TikTok과 YouTube에서 수집된 트렌드 데이터를 체계적으로 축적하고 시계열 분석을 수행할 수 있는 기술적 기반을 성공적으로 마련했습니다.

## 2. 기술적 성과 및 해결된 문제

### 2.1. 하이브리드 데이터베이스 전략 채택
- **문제:** 작업 지시서의 PostgreSQL은 강력하지만, 초기 개발 단계에서는 설치 및 설정의 부담이 컸습니다.
- **해결:** **"초기에는 SQLite로 빠르게, 나중에는 PostgreSQL로 견고하게"** 가는 하이브리드 전략을 채택했습니다. 이를 통해 서버 설치 없이 신속하게 데이터 저장 로직을 개발하고 검증할 수 있었으며, 향후 프로덕션 환경 전환 시 `database_manager.py`의 접속 정보만 수정하면 되도록 설계하여 유연성을 확보했습니다.

### 2.2. DB 추상화 및 모듈화
- **문제:** 각 스크레이퍼에 DB 코드를 개별적으로 작성할 경우, 중복 코드가 발생하고 유지보수가 어려워집니다.
- **해결:** 모든 DB 로직을 `database_manager.py`로 추상화하고 분리했습니다. 스크레이퍼는 `import` 후 `add_song()`, `add_trend()`와 같은 간단한 함수만 호출하면 되므로, 관심사가 명확히 분리되고 코드의 가독성과 재사용성이 크게 향상되었습니다.

### 2.3. 안전한 동시 실행 문제 해결
- **문제:** 여러 스크레이퍼가 동시에 SQLite 파일에 접근할 경우, "database is locked" 오류가 발생하여 데이터 유실의 위험이 있었습니다.
- **해결:** `run_all_scrapers.sh` 스크립트 내에서 `&&` 연산자나 순차 실행 구문을 사용하여, 각 스크레이퍼가 앞선 작업의 성공을 확인한 후 순서대로 실행되도록 보장함으로써 데이터의 정합성을 확보했습니다.

### 2.4. 가상환경 실행 문제 해결
- **문제:** `playwright` 라이브러리를 찾지 못하는 `ModuleNotFoundError`가 발생했습니다.
- **해결:** 실행 스크립트(`run_all_scrapers.sh`)가 시스템의 기본 파이썬이 아닌, 프로젝트의 가상환경(`venv/bin/python3`)에 설치된 파이썬을 명시적으로 사용하도록 경로를 수정하여 문제를 해결했습니다. 이를 통해 프로젝트의 독립성과 재현성을 보장했습니다.

## 3. 향후 과제 및 발전 방향

### 3.1. 프로덕션용 PostgreSQL 전환
- **과제:** 현재의 SQLite는 MVP 단계에 최적화되어 있습니다. 향후 실제 서버에 배포하고 24시간 자동화를 구축하는 시점에는 동시성 제어와 성능이 더 뛰어난 PostgreSQL로 전환해야 합니다.
- **방향:** `database_manager.py`의 DB 연결 부분만 `psycopg2` 라이브러리를 사용하도록 수정하고, `config.ini` 파일을 다시 도입하여 DB 접속 정보를 관리합니다.

### 3.2. 스크레이퍼 `headless` 모드 전환
- **과제:** 현재 스크레이퍼는 디버깅 편의를 위해 `headless=False` (브라우저 UI가 보임) 상태로 실행됩니다.
- **방향:** 서버 환경에서의 자동화를 위해 `headless=True`로 전환하고, 안티-스크래핑 봇 탐지에 대응하기 위한 `playwright-extra`의 `stealth` 플러그인 적용 등 안정성 테스트를 수행해야 합니다.

### 3.3. 정기 실행 자동화 (스케줄링)
- **과제:** 현재는 수동으로 `./run_all_scrapers.sh`를 실행해야만 데이터가 수집됩니다.
- **방향:** Linux/macOS의 `cron`이나 Windows의 `작업 스케줄러`를 사용하여 매일 특정 시간에 `run_all_scrapers.sh` 스크립트가 자동으로 실행되도록 스케줄링해야 합니다.

### 3.4. 데이터 분석 및 시각화 파이프라인 구축
- **과제:** 데이터가 성공적으로 축적되고 있으므로, 이 데이터를 활용할 방법이 필요합니다.
- **방향:** 축적된 시계열 데이터를 바탕으로 특정 음악의 순위 변화 추이, 새로운 트렌드의 등장, 플랫폼 간의 인기곡 비교 등을 분석하고 시각화하는 별도의 분석 스크립트나 대시보드(예: Streamlit, Dash)를 구축하는 단계를 진행할 수 있습니다.

## 4. 전체 프로젝트에서의 위치

이번 PoC 4는 개별적으로 존재하던 데이터 수집기들을 **하나의 유기적인 데이터 파이프라인으로 통합**하는 핵심적인 단계였습니다. 이로써 'Short-form Music Trend Analysis Service'는 일회성 데이터 수집을 넘어, **지속적으로 데이터를 축적하고 분석할 수 있는 백엔드 시스템의 첫 번째 버전**을 갖추게 되었습니다. 앞으로 진행될 모든 데이터 분석, AI 모델링, 사용자 서비스는 이 파이프라인을 통해 축적된 데이터를 기반으로 하게 될 것입니다.
